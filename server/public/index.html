<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>AI Interview Coach — Realtime Voice</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    :root {
      --bg: #0f1623;
      --panel: #1a2332;
      --panel-dark: #121a27;
      --text: #e6eefc;
      --muted: #9fb3d1;
      --accent: #4ad1a8;
      --accent-2: #4aa3ff;
      --danger: #ff6b6b;
      --shadow: rgba(0,0,0,0.35);
      --radius: 16px;
    }
    * { box-sizing: border-box; }
    body {
      margin: 0; padding: 32px;
      font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, "Helvetica Neue", Arial;
      color: var(--text); background: linear-gradient(180deg, #0d1420 0%, #0b1120 100%);
    }
    h1 {
      margin: 0 0 8px; text-align: center; letter-spacing: 0.5px;
      font-weight: 800; font-size: 48px; color: #7fb3ff;
      text-shadow: 0 6px 24px rgba(74,163,255,0.25);
    }
    .subtitle { text-align: center; color: var(--muted); margin-bottom: 24px; }

    .panel {
      background: var(--panel);
      box-shadow: 0 12px 28px var(--shadow);
      border-radius: var(--radius);
      padding: 18px;
      border: 1px solid #1e2a3d;
    }

    .grid {
      display: grid; gap: 16px;
      grid-template-columns: repeat(6, minmax(0, 1fr));
    }
    .grid .field { grid-column: span 2; display: flex; flex-direction: column; gap: 6px; }
    label { color: var(--muted); font-size: 13px; }
    select {
      width: 100%; padding: 12px 12px; border-radius: 10px;
      background: var(--panel-dark); color: var(--text); border: 1px solid #26344a;
      outline: none; transition: border .15s ease;
    }
    select:focus { border-color: var(--accent-2); }

    .mode-toggle { display: inline-flex; background: var(--panel-dark); border: 1px solid #26344a; border-radius: 10px; overflow: hidden; box-shadow: 0 6px 14px rgba(74,163,255,0.12); }
    .mode-toggle button { background: transparent; color: var(--text); padding: 10px 14px; border: none; cursor: pointer; transition: background .2s ease, color .2s ease, transform .15s ease; }
    .mode-toggle button.active { background: var(--accent-2); color: #061226; transform: translateY(-1px); }
    .switch-row { display:flex; justify-content:center; margin: 10px 0 6px; }
    @keyframes fadeInUp { from { opacity: 0; transform: translateY(6px); } to { opacity: 1; transform: none; } }
    .appear { animation: fadeInUp .25s ease both; }

    .stage {
      margin-top: 18px;
      padding: 24px; border-radius: var(--radius);
      background: var(--panel);
      display: flex; flex-direction: column; align-items: center; gap: 16px;
      border: 1px solid #1e2a3d;
    }
    .timer {
      font-size: 54px; font-weight: 800; letter-spacing: 3px; color: #9fc4ff;
      text-shadow: 0 10px 24px rgba(159,196,255,.25);
    }
    /* Realtime visualizer canvas */
    #visualizer {
      width: min(560px, 92%);
      height: 200px;
      background: linear-gradient(135deg, #4aa3ff 0%, #a07bff 40%, #4ad1a8 100%);
      border-radius: 12px;
      box-shadow: 0 10px 32px rgba(74,163,255,0.15);
      display: block;
    }
    .buttons { display: flex; gap: 16px; }
    button {
      padding: 12px 16px; border: none; border-radius: 10px; cursor: pointer;
      font-weight: 700; letter-spacing: .3px; color: #0b1220;
    }
    #startBtn { background: var(--accent); }
    #stopBtn { background: #2d3a52; color: #c9d6ea; }
    #stopBtn.enabled { background: #3b4f70; }
    #stopBtn.danger { background: var(--danger); color: #fff; }

    .log {
      background: #0b1220; color: #cfe1ff; border-radius: 12px; padding: 12px;
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", monospace;
      width: min(860px, 100%); max-height: 220px; overflow: auto; border: 1px solid #1b2840;
    }
    .text-box { width: min(860px, 100%); min-height: 260px; max-height: 420px; overflow: auto; }
    .msg { margin: 6px 0; }
    .msg.user { color: #b0ffc8; }
    .msg.ai { color: #cfe1ff; }
    .text-input { display: flex; gap: 8px; width: min(860px, 100%); }
    .text-input input { flex: 1; padding: 12px; border-radius: 10px; border: 1px solid #26344a; background: var(--panel-dark); color: var(--text); }
    .text-input button { padding: 12px 16px; border-radius: 10px; border: none; cursor: pointer; font-weight: 700; }
    #textSendBtn { background: var(--accent-2); color: #061226; }

    /* FAQ styles */
    .faq-panel { margin-top: 18px; }
    .faq-title { text-align:center; color: #9fb3d1; margin: 4px 0 10px; font-weight: 700; letter-spacing: .3px; }
    .faq-actions { display:flex; justify-content:center; gap:10px; margin-bottom: 12px; }
    #genFaqBtn { background: #2d3a52; color: #cfe1ff; }
    #genFaqBtn.active { background: var(--accent-2); color: #061226; }
    .faq-list { width: min(860px, 100%); margin: 0 auto; }
    details.faq { background: #0b1220; border: 1px solid #1b2840; border-radius: 10px; padding: 10px 12px; margin: 8px 0; box-shadow: 0 6px 14px rgba(0,0,0,.18); }
    details.faq[open] { border-color: #2a3e60; }
    details.faq summary { cursor: pointer; list-style: none; color: #cfe1ff; font-weight: 700; }
    details.faq summary::-webkit-details-marker { display:none; }
    .faq-a { color: #9fb3d1; margin-top: 6px; line-height: 1.5; }

    
    @media (max-width: 980px) {
      .grid { grid-template-columns: repeat(2, 1fr); }
      .grid .field { grid-column: span 1; }
    }
  </style>
</head>
<body>
  <h1>AI Interview Coach</h1>
  <div class="subtitle">Practice your interview skills with AI-powered simulation</div>

  <!-- Controls -->
  <div class="panel">
    <div class="grid">
      <div class="field">
        <label>Company</label>
        <select id="company">
          <option>Google</option><option>Microsoft</option><option>Amazon</option>
          <option>Meta</option><option>Apple</option><option>OpenAI</option>
          <option selected>Generic</option>
        </select>
      </div>
      <div class="field">
        <label>Job Role</label>
        <select id="role">
          <option>Software Engineer</option>
          <option>Data Scientist</option>
          <option>Machine Learning Engineer</option>
          <option>Business Analyst</option>
          <option>Product Manager</option>
          <option selected>Software Engineer</option>
        </select>
      </div>
      <div class="field">
        <label>Experience Level</label>
        <select id="experience">
          <option>Intern</option><option>Junior</option>
          <option selected>Mid-level</option><option>Senior</option><option>Lead</option>
        </select>
      </div>
      <div class="field">
        <label>Interview Type</label>
        <select id="type">
          <option selected>Technical</option><option>Behavioral</option><option>System Design</option>
          <option>Case Study</option>
        </select>
      </div>
      <div class="field">
        <label>Difficulty</label>
        <select id="difficulty">
          <option>Easy</option><option selected>Medium</option><option>Hard</option>
        </select>
      </div>
      <div class="field">
        <label>Duration</label>
        <select id="duration">
          <option value="3">3 minutes</option>
          <option value="5" selected>5 minutes</option>
          <option value="10">10 minutes</option>
          <option value="15">15 minutes</option>
        </select>
      </div>
    </div>
  </div>

  <!-- Mode Switch -->
  <div class="switch-row">
    <div class="mode-toggle" id="modeToggle">
      <button id="modeVoice" class="active">Voice</button>
      <button id="modeText">Text</button>
    </div>
  </div>

  <!-- Stage: Voice -->
  <div class="stage" id="voiceStage">
    <div id="timer" class="timer">00:00</div>
    <canvas id="visualizer"></canvas>
    <div class="buttons">
      <button id="startBtn">▶️ START INTERVIEW</button>
      <button id="stopBtn" disabled>⏹ END INTERVIEW</button>
    </div>
    <audio id="remote" autoplay></audio>
    <div id="log" class="log"></div>
  </div>

  <!-- Stage: Text -->
  <div class="stage" id="textStage" style="display:none">
    <div id="textLog" class="log text-box"></div>
    <div class="text-input">
      <input id="textInput" placeholder="Type your answer…" />
      <button id="textSendBtn" disabled>Send</button>
    </div>
    <div class="buttons">
      <button id="textStartBtn">START INTERVIEW</button>
      <button id="textEndBtn" disabled>END INTERVIEW</button>
    </div>
  </div>

  <!-- FAQs -->
  <div class="panel faq-panel">
    <div class="faq-title">Study: FAQs</div>
    <div class="faq-actions">
      <button id="genFaqBtn">Generate FAQs from selections</button>
    </div>
    <div id="faqList" class="faq-list"></div>
  </div>

<script>
  const companyEl = document.getElementById('company');
  const roleEl = document.getElementById('role');
  const experienceEl = document.getElementById('experience');
  const typeEl = document.getElementById('type');
  const difficultyEl = document.getElementById('difficulty');
  const durationEl = document.getElementById('duration');

  const startBtn = document.getElementById('startBtn');
  const stopBtn  = document.getElementById('stopBtn');
  const timerEl  = document.getElementById('timer');
  const logEl    = document.getElementById('log');
  const remoteEl = document.getElementById('remote');
  const vizCanvas = document.getElementById('visualizer');
  let vizCtx, audioCtx, analyserMic, analyserRemote, vizAnim;
  // Mode controls and sections
  const modeToggle = document.getElementById('modeToggle');
  const modeVoiceBtn = document.getElementById('modeVoice');
  const modeTextBtn  = document.getElementById('modeText');
  const voiceStage = document.getElementById('voiceStage');
  const textStage = document.getElementById('textStage');
  let mode = 'voice';

  let pc, dc, localStream, interval, secs = 0, running = false;
  let startedOnce = false; // ensures kickoff only once per session
  let interviewStarted = false; // kickoff sent
  let heardInterviewerOnce = false; // remote audio detected
  let lastRemoteActiveMs = 0;

  function resetFlags(){
    startedOnce = false;
    interviewStarted = false;
    heardInterviewerOnce = false;
    lastRemoteActiveMs = 0;
    secs = 0;
    running = false;
  }

  function closeMedia(){
    try { localStream?.getTracks()?.forEach(t => t.stop()); } catch {}
    localStream = null;
    try { remoteEl.srcObject = null; } catch {}
  }

  function closeRTC(){
    try { dc?.close(); } catch {}
    try { pc?.getSenders()?.forEach(s => { try { s.track?.stop(); } catch {} }); } catch {}
    try { pc?.close(); } catch {}
    dc = null; pc = null;
  }

  function log(t){ logEl.textContent += t + "\n"; logEl.scrollTop = logEl.scrollHeight; }

  function formatMMSS(s){
    const m = Math.floor(s/60).toString().padStart(2,'0');
    const ss = (s%60).toString().padStart(2,'0');
    return `${m}:${ss}`;
  }

  function startTimer(){
    secs = 0;
    timerEl.textContent = "00:00";
    interval = setInterval(() => {
      secs++; timerEl.textContent = formatMMSS(secs);
    }, 1000);
  }
  function stopTimer(){ clearInterval(interval); }

  // --- Visualizer helpers ---
  function resizeCanvas(){
    if (!vizCanvas) return;
    const dpr = Math.max(window.devicePixelRatio || 1, 1);
    const cssW = vizCanvas.clientWidth || 560;
    const cssH = vizCanvas.clientHeight || 200;
    vizCanvas.width = Math.floor(cssW * dpr);
    vizCanvas.height = Math.floor(cssH * dpr);
    if (vizCtx) {
      vizCtx.setTransform(1, 0, 0, 1, 0, 0);
      vizCtx.scale(dpr, dpr);
    }
  }

  function startVisualizer(micStream){
    try {
      vizCtx = vizCanvas.getContext('2d');
      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      analyserMic = audioCtx.createAnalyser();
      analyserMic.fftSize = 512;
      const srcMic = audioCtx.createMediaStreamSource(micStream);
      srcMic.connect(analyserMic);
      window.addEventListener('resize', resizeCanvas);
      resizeCanvas();
      drawVisualizer();
      startMicSilenceMonitor();
    } catch (e) {
      log('Visualizer error: ' + e.message);
    }
  }

  function attachRemoteVisualizer(remoteStream){
    if (!audioCtx) return;
    try {
      analyserRemote = audioCtx.createAnalyser();
      analyserRemote.fftSize = 512;
      const srcRemote = audioCtx.createMediaStreamSource(remoteStream);
      srcRemote.connect(analyserRemote);
    } catch (e) {
      // Non-fatal
    }
  }

  function drawWave(data, color, alpha){
    const w = vizCanvas.clientWidth;
    const h = vizCanvas.clientHeight;
    const len = data.length;
    const slice = w / len;
    vizCtx.save();
    vizCtx.globalAlpha = alpha;
    vizCtx.lineWidth = 2;
    vizCtx.strokeStyle = color;
    vizCtx.beginPath();
    for (let i = 0; i < len; i++) {
      const v = data[i] / 128.0;
      const y = (v * h) / 2; // center around midline
      const x = i * slice;
      if (i === 0) vizCtx.moveTo(x, y);
      else vizCtx.lineTo(x, y);
    }
    vizCtx.stroke();
    vizCtx.restore();
  }

  function drawVisualizer(){
    if (!vizCtx) return;
    vizAnim = requestAnimationFrame(drawVisualizer);
    // Clear to transparent to let CSS gradient show
    vizCtx.clearRect(0, 0, vizCanvas.clientWidth, vizCanvas.clientHeight);

    if (analyserMic) {
      const buf = new Uint8Array(analyserMic.fftSize);
      analyserMic.getByteTimeDomainData(buf);
      drawWave(buf, '#4aa3ff', 0.9);
    }
    if (analyserRemote) {
      const buf2 = new Uint8Array(analyserRemote.fftSize);
      analyserRemote.getByteTimeDomainData(buf2);
      drawWave(buf2, '#4ad1a8', 0.7);
      // detect interviewer activity
      let sum = 0;
      for (let i = 0; i < buf2.length; i++) sum += Math.abs(buf2[i] - 128);
      const amp = (sum / buf2.length) / 128;
      if (amp > 0.03) {
        heardInterviewerOnce = true;
        lastRemoteActiveMs = Date.now();
      }
    }
  }

  // --- Silence monitor (mic) ---
  let silenceInt = null, silenceSec = 0, silencePing1 = false, silencePing2 = false;
  function startMicSilenceMonitor(){
    try { if (silenceInt) clearInterval(silenceInt); } catch{}
    silenceSec = 0; silencePing1 = false; silencePing2 = false;
    silenceInt = setInterval(() => {
      if (!running || !analyserMic) return;
      // Only monitor silence after the interviewer has spoken at least once
      if (!heardInterviewerOnce) return;
      const buf = new Uint8Array(analyserMic.fftSize);
      analyserMic.getByteTimeDomainData(buf);
      // crude amplitude around midpoint 128
      let sum = 0;
      for (let i = 0; i < buf.length; i++) sum += Math.abs(buf[i] - 128);
      const amp = (sum / buf.length) / 128; // 0..~1
      const silentMic = amp < 0.02;

      // Also ensure interviewer is not currently speaking
      let remoteSilent = true;
      if (analyserRemote) {
        const r = new Uint8Array(analyserRemote.fftSize);
        analyserRemote.getByteTimeDomainData(r);
        let rsum = 0; for (let i = 0; i < r.length; i++) rsum += Math.abs(r[i] - 128);
        const ramp = (rsum / r.length) / 128;
        remoteSilent = ramp < 0.03;
        if (!remoteSilent) lastRemoteActiveMs = Date.now();
      }

      // Give at least 1s after interviewer finished speaking before counting
      const quietSinceRemote = Date.now() - lastRemoteActiveMs;
      const okWindow = quietSinceRemote > 1000;

      if (silentMic && remoteSilent && okWindow) silenceSec += 0.5; else silenceSec = 0;
      if (silenceSec >= 10 && !silencePing1 && dc?.readyState === 'open') {
        dc.send(JSON.stringify({
          type: 'response.create',
          response: { instructions: "Are you there? Please go ahead when you're ready." }
        }));
        silencePing1 = true;
      }
      if (silenceSec >= 20 && !silencePing2 && dc?.readyState === 'open') {
        dc.send(JSON.stringify({
          type: 'response.create',
          response: { instructions: "I'll move to the next question. Please answer when ready; do not restart or reintroduce yourself." }
        }));
        silencePing2 = true;
      }
    }, 500);
  }
  function stopMicSilenceMonitor(){
    try { if (silenceInt) clearInterval(silenceInt); } catch{}
    silenceInt = null; silenceSec = 0; silencePing1 = false; silencePing2 = false;
  }

  function stopVisualizer(){
    try { if (vizAnim) cancelAnimationFrame(vizAnim); } catch {}
    vizAnim = null;
    try { window.removeEventListener('resize', resizeCanvas); } catch {}
    try { audioCtx?.close(); } catch {}
    audioCtx = null; vizCtx = null; analyserMic = null; analyserRemote = null;
    stopMicSilenceMonitor();
  }

  async function startInterview(){
    // Make sure any previous session is fully closed
    try { stopVisualizer(); } catch {}
    stopMicSilenceMonitor?.();
    closeRTC();
    closeMedia();
    resetFlags();

    startBtn.disabled = true;
    stopBtn.disabled = false;
    stopBtn.classList.add('enabled');
    log('Starting interview…');

    try {
      // 1) ask backend for ephemeral key with your selected config
      const cfg = {
        company: companyEl.value,
        role: roleEl.value,
        experience: experienceEl.value,
        type: typeEl.value,
        difficulty: difficultyEl.value,
        durationMinutes: Number(durationEl.value)
      };

      const ekResp = await fetch('/session', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(cfg)
      });
      const { ephemeral_key } = await ekResp.json();
      if(!ephemeral_key) throw new Error('No ephemeral key returned');
      log('Ephemeral key received.');

      // 2) get mic
      localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const track = localStream.getAudioTracks()[0];
      startVisualizer(localStream);

      // 3) set up peer connection
      pc = new RTCPeerConnection();
      pc.ontrack = (e) => { 
        remoteEl.srcObject = e.streams[0];
        attachRemoteVisualizer(e.streams[0]);
      };
      pc.addTrack(track, localStream);

      // data channel for events/messages
      dc = pc.createDataChannel('oai-events');
      dc.onopen = () => {
        log('DataChannel open.');
        if (!startedOnce && running && pc?.connectionState !== 'closed') {
          // Single controlled kickoff so the interviewer begins immediately, once.
          dc.send(JSON.stringify({
            type: 'response.create',
            response: {
              instructions: 'Begin the interview now. Greet once as Sarah, then ask the first question. Do not reintroduce yourself later and do not answer on behalf of the candidate.'
            }
          }));
          startedOnce = true;
          interviewStarted = true;
        }
      };
      // Ignore any incoming messages for UI
      dc.onmessage = () => {};

      const offer = await pc.createOffer({ offerToReceiveAudio: true });
      await pc.setLocalDescription(offer);

      // 4) send SDP to OpenAI with the ephemeral token
      const sdpResp = await fetch('https://api.openai.com/v1/realtime?model=gpt-realtime', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${ephemeral_key}`,
          'Content-Type': 'application/sdp'
        },
        body: offer.sdp
      });
      if (!sdpResp.ok) {
        const txt = await sdpResp.text();
        throw new Error('Realtime SDP exchange failed: ' + txt);
      }
      const answerSDP = await sdpResp.text();
      await pc.setRemoteDescription({ type: 'answer', sdp: answerSDP });

      running = true;
      startTimer();
      log('Connected. The interviewer will begin shortly…');

      // No auto-nudge; let interviewer begin naturally to avoid double greetings.

    } catch(e) {
      log('Error: ' + e.message);
      startBtn.disabled = false;
      stopBtn.disabled = true;
      stopBtn.classList.remove('enabled');
    }
  }

  async function endInterview(manual = false) {
    if (!running) return;
    running = false;
    stopTimer();
    stopVisualizer();
    stopMicSilenceMonitor?.();
    stopBtn.disabled = true;
    stopBtn.classList.remove('enabled');
    stopBtn.classList.add('danger');
    log('Ending interview…');

    // Close everything immediately to ensure a fresh next start
    closeRTC();
    closeMedia();
    resetFlags();
    startBtn.disabled = false;
    log('Interview session closed.');
  }


  startBtn.onclick = startInterview;
  stopBtn.onclick = () => endInterview(true);

  // Text mode elements/state
  const textLogEl = document.getElementById('textLog');
  const textInputEl = document.getElementById('textInput');
  const textSendBtn = document.getElementById('textSendBtn');
  const textStartBtn = document.getElementById('textStartBtn');
  const textEndBtn = document.getElementById('textEndBtn');
  let textRunning = false;
  let textMessages = [];

  function addMsg(role, text){
    const div = document.createElement('div');
    div.className = 'msg ' + (role === 'user' ? 'user' : 'ai');
    div.textContent = (role === 'user' ? 'You: ' : 'Sarah: ') + text;
    textLogEl.appendChild(div); textLogEl.scrollTop = textLogEl.scrollHeight;
  }

  async function chatRequest(messages){
    const cfg = {
      company: companyEl.value,
      role: roleEl.value,
      experience: experienceEl.value,
      type: typeEl.value,
      difficulty: difficultyEl.value,
      durationMinutes: Number(durationEl.value)
    };
    const resp = await fetch('/chat', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ cfg, messages })
    });
    if (!resp.ok) throw new Error('Chat error: ' + await resp.text());
    const json = await resp.json();
    return json.text || '';
  }

  async function startTextInterview(){
    if (textRunning) return;
    // ensure voice is off when switching modes
    try { endInterview(true); } catch {}
    textRunning = true; textStartBtn.disabled = true; textEndBtn.disabled = false; textSendBtn.disabled = false;
    textLogEl.textContent = '';
    textMessages = [{ role: 'user', content: 'Begin the interview now. Greet once as Sarah, then ask the first question.' }];
    addMsg('user', 'Begin the interview now.');
    try {
      const reply = await chatRequest(textMessages);
      textMessages.push({ role: 'assistant', content: reply });
      addMsg('assistant', reply);
    } catch(e){ addMsg('assistant', 'Error: ' + e.message); }
  }

  async function sendText(){
    if (!textRunning) return;
    const val = textInputEl.value.trim();
    if (!val) return;
    textInputEl.value = '';
    textMessages.push({ role: 'user', content: val });
    addMsg('user', val);
    try {
      const reply = await chatRequest(textMessages);
      textMessages.push({ role: 'assistant', content: reply });
      addMsg('assistant', reply);
    } catch(e){ addMsg('assistant', 'Error: ' + e.message); }
  }

  function endTextInterview(){
    textRunning = false; textStartBtn.disabled = false; textEndBtn.disabled = true; textSendBtn.disabled = true;
    textMessages = [];
  }

  textStartBtn.onclick = startTextInterview;
  textEndBtn.onclick = endTextInterview;
  textSendBtn.onclick = sendText;
  textInputEl.addEventListener('keydown', (e)=>{ if(e.key==='Enter') sendText(); });

  function setMode(newMode){
    if (newMode === mode) return;
    mode = newMode;
    if (mode === 'voice') {
      textStage.style.display = 'none';
      voiceStage.style.display = '';
      voiceStage.classList.add('appear'); setTimeout(()=>voiceStage.classList.remove('appear'), 300);
      modeVoiceBtn.classList.add('active');
      modeTextBtn.classList.remove('active');
    } else {
      // ensure voice session is closed before switching
      try { endInterview(true); } catch {}
      voiceStage.style.display = 'none';
      textStage.style.display = '';
      textStage.classList.add('appear'); setTimeout(()=>textStage.classList.remove('appear'), 300);
      modeTextBtn.classList.add('active');
      modeVoiceBtn.classList.remove('active');
    }
  }

  modeVoiceBtn.onclick = () => setMode('voice');
  modeTextBtn.onclick  = () => setMode('text');

  // --- FAQs ---
  const faqListEl = document.getElementById('faqList');
  const genFaqBtn = document.getElementById('genFaqBtn');

  function renderFaqs(items){
    faqListEl.innerHTML = '';
    if (!items || !items.length) {
      const d = document.createElement('div'); d.style.color = '#9fb3d1'; d.style.textAlign='center'; d.textContent = 'No FAQs yet. Click Generate.'; faqListEl.appendChild(d); return;
    }
    for (const it of items) {
      const det = document.createElement('details'); det.className = 'faq';
      const sum = document.createElement('summary'); sum.textContent = it.q;
      const ans = document.createElement('div'); ans.className = 'faq-a'; ans.textContent = it.a;
      det.appendChild(sum); det.appendChild(ans); faqListEl.appendChild(det);
    }
  }

  async function generateFaqs(){
    genFaqBtn.classList.add('active'); genFaqBtn.disabled = true; genFaqBtn.textContent = 'Generating…';
    try {
      const cfg = {
        company: companyEl.value,
        role: roleEl.value,
        experience: experienceEl.value,
        type: typeEl.value,
        difficulty: difficultyEl.value,
      };
      const resp = await fetch('/faq', { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ cfg, count: 8 }) });
      const json = await resp.json();
      renderFaqs(json.faqs || []);
    } catch(e){
      renderFaqs([]);
    } finally {
      genFaqBtn.disabled = false; genFaqBtn.classList.remove('active'); genFaqBtn.textContent = 'Generate FAQs from selections';
    }
  }
  genFaqBtn.onclick = generateFaqs;
  // initial placeholder
  renderFaqs([]);

  // Auto-stop after selected duration (soft stop: ask for feedback)
  setInterval(() => {
    if (!running) return;
    const maxSecs = Number(durationEl.value) * 60;
    if (secs >= maxSecs) endInterview(false);
  }, 1000);
</script>
</body>
</html>
